"""Incremental placement module combining rule-based heuristic with a lightweight
Q-learning (multi-armed bandit style) component for new incoming items.

Function: place_new_item(new_item: dict) -> str

Inputs & Files (expected in CWD):
  - placement_recommendations.csv  (existing placements; columns: item_id,recommended_location)
  - warehouse_layout.csv OR locations_data.csv (layout with columns: location_id,x_coord,y_coord,max_size,max_weight[,is_shelf])

new_item dict example:
    new_item = {
        "item_id": "ITEM123",
        "demand_frequency": 20,
        "dimensions": 5,              # Either numeric volume OR string "h x w x d"
        "current_stock": 10,
        "weight_per_unit": 2
    }

Logic Steps:
 1. Load layout & existing placements; determine available (unoccupied) shelves.
 2. Rule-based: compute Euclidean distance to packing station (0,0) and sort ascending.
 3. Feasibility: dimensions (volume) <= max_size and (current_stock * weight_per_unit) <= max_weight.
 4. RL (epsilon-greedy Q-learning) over feasible shelves:
       - State bucket: demand_bucket = floor(demand_frequency / DEMAND_BUCKET_SIZE)
       - Actions: feasible shelf IDs
       - Reward: (1 - normalized_distance) + DEMAND_WEIGHT * demand_norm
       - Q update: Q[s,b] <- (1-alpha)*Q + alpha*reward (single-step episode)
       - Train for N_EPISODES per call (lightweight, cumulative across runs via pickle file).
 5. Choose best shelf by highest Q value for the state bucket; fallback to first feasible (by distance) if tie/empty.
 6. Append placement to placement_recommendations.csv persistently.

Persistence:
  - Q table stored in 'placement_q_table.pkl' as dict: {(demand_bucket, shelf_id): q_value}

Returns:
  - Success: "New item ITEM123 placed at location L5"
  - Failure (no feasible shelves): "No suitable location found for item ITEM123"

Extensibility Notes:
  - Replace bandit with full Q-learning by modeling post-placement state if sequential decisions required.
  - Add shelf rebalancing / dynamic evaporation to Q values to prevent overfitting.
  - Incorporate congestion / aisle travel time instead of pure Euclidean distance.

Author: Auto-generated by GitHub Copilot
"""
from __future__ import annotations

import math
import os
import pickle
import argparse
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd

Q_TABLE_PATH = "placement_q_table.pkl"
PLACEMENTS_FILE = "placement_recommendations.csv"
LAYOUT_CANDIDATE_FILENAMES = ["warehouse_layout.csv", "locations_data.csv", "locations_data_extended.csv"]  # extended file added

# RL Hyperparameters
ALPHA = 0.3            # learning rate
EPSILON = 0.15         # exploration probability
N_EPISODES = 40        # episodes per new item (small to stay fast)
DEMAND_BUCKET_SIZE = 25  # bucket width for demand frequency
DEMAND_WEIGHT = 0.1     # weight coefficient for demand in reward


def _load_q_table() -> Dict[Tuple[int, str], float]:
    if os.path.exists(Q_TABLE_PATH):
        try:
            with open(Q_TABLE_PATH, "rb") as f:
                return pickle.load(f)
        except Exception:
            return {}
    return {}


def _save_q_table(q: Dict[Tuple[int, str], float]):
    with open(Q_TABLE_PATH, "wb") as f:
        pickle.dump(q, f)


def _parse_volume(dim_value) -> Optional[float]:
    """Parse volume from input which can be:
        - numeric (int/float): interpreted directly as volume
        - string formatted like "h x w x d" (any separators x,*,X or spaces)
      Returns None if cannot parse.
    """
    if dim_value is None:
        return None
    if isinstance(dim_value, (int, float)):
        return float(dim_value)
    if isinstance(dim_value, str):
        # Extract first 3 numbers; if only 1 treat as direct volume
        parts = [p for p in dim_value.replace("*", "x").replace("X", "x").replace(" ", "x").split("x") if p]
        nums = []
        for p in parts:
            try:
                nums.append(float(p))
            except ValueError:
                continue
        if not nums:
            return None
        if len(nums) == 1:
            return nums[0]
        while len(nums) < 3:
            nums.append(1.0)  # assume missing dimension = 1
        h, w, d = nums[:3]
        return h * w * d
    return None


def _load_layout(layout_override: Optional[str] = None) -> pd.DataFrame:
    """Load a layout; if layout_override provided, use it; else search candidates."""
    candidates = [layout_override] if layout_override else LAYOUT_CANDIDATE_FILENAMES
    for fname in candidates:
        if fname and os.path.exists(fname):
            df = pd.read_csv(fname)
            required = {"location_id", "x_coord", "y_coord", "max_size", "max_weight"}
            missing = required - set(df.columns)
            if missing:
                raise ValueError(f"Layout file {fname} is missing required columns: {missing}")
            return df
    raise FileNotFoundError("No warehouse layout file found (checked: " + ", ".join(candidates) + ")")


def _load_existing_placements() -> pd.DataFrame:
    if os.path.exists(PLACEMENTS_FILE):
        return pd.read_csv(PLACEMENTS_FILE)
    return pd.DataFrame(columns=["item_id", "recommended_location"])


def _get_available_shelves(layout_df: pd.DataFrame, placements_df: pd.DataFrame) -> pd.DataFrame:
    occupied = set(placements_df["recommended_location"].dropna().tolist())
    # If an is_shelf column exists, keep only True
    df = layout_df.copy()
    if "is_shelf" in df.columns:
        df = df[df["is_shelf"] == True]  # noqa: E712
    # Remove packing station heuristically (at origin or id contains 'packing')
    df = df[~df["location_id"].str.lower().str.contains("packing")]
    df = df[(df["x_coord"] != 0) | (df["y_coord"] != 0)]
    return df[~df["location_id"].isin(occupied)].copy()


def _feasible_shelves(available_df: pd.DataFrame, volume: float, total_weight: float) -> pd.DataFrame:
    return available_df[(volume <= available_df["max_size"]) & (total_weight <= available_df["max_weight"])]


def _compute_distances(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["distance"] = np.sqrt(df["x_coord"] ** 2 + df["y_coord"] ** 2)
    return df


def _demand_bucket(demand: float) -> int:
    return int(demand // DEMAND_BUCKET_SIZE)


def _epsilon_greedy_select(q_table: Dict[Tuple[int, str], float], demand_bucket: int, shelves: List[str], epsilon: float) -> str:
    if not shelves:
        raise ValueError("No shelves provided to epsilon-greedy selection")
    if np.random.rand() < epsilon:
        return np.random.choice(shelves)
    # Exploit: pick shelf with max Q
    best_shelf = None
    best_q = -float("inf")
    for sid in shelves:
        q = q_table.get((demand_bucket, sid), 0.0)
        if q > best_q:
            best_q = q
            best_shelf = sid
    return best_shelf if best_shelf is not None else np.random.choice(shelves)


def _reward(distance: float, max_distance: float, demand_frequency: float) -> float:
    if max_distance <= 0:
        norm_dist_component = 1.0
    else:
        norm_dist_component = 1.0 - (distance / max_distance)  # closer -> larger positive
    demand_norm = demand_frequency / (demand_frequency + 10.0)
    return norm_dist_component + DEMAND_WEIGHT * demand_norm


def place_new_item(new_item: dict) -> str:
    """Place a new item using hybrid rule-based + Q-learning (bandit) approach.

    Side-effect: appends placement to placement_recommendations.csv and updates Q table.
    """
    return _place_new_item_core(new_item)


def _place_new_item_core(new_item: dict, layout_override: Optional[str] = None) -> str:
    """Internal core with optional layout override (batch support)."""
    required_keys = {"item_id", "demand_frequency", "dimensions", "current_stock", "weight_per_unit"}
    missing = required_keys - set(new_item.keys())
    if missing:
        raise ValueError(f"new_item dict missing required keys: {missing}")

    # Parse volume
    volume = _parse_volume(new_item.get("dimensions"))
    if volume is None or volume <= 0:
        return f"No suitable location found for item {new_item['item_id']}"  # cannot place with invalid volume

    total_weight = float(new_item["current_stock"]) * float(new_item["weight_per_unit"])
    demand_freq = float(new_item["demand_frequency"])

    # Load data
    layout_df = _load_layout(layout_override)
    placements_df = _load_existing_placements()
    available_df = _get_available_shelves(layout_df, placements_df)
    if available_df.empty:
        return f"No suitable location found for item {new_item['item_id']}"

    # Feasible subset
    feasible_df = _feasible_shelves(available_df, volume, total_weight)
    if feasible_df.empty:
        return f"No suitable location found for item {new_item['item_id']}"

    # Compute distances & sort for rule-based baseline
    feasible_df = _compute_distances(feasible_df)
    feasible_df.sort_values(by=["distance", "location_id"], inplace=True)

    # RL training (bandit per state bucket)
    q_table = _load_q_table()
    bucket = _demand_bucket(demand_freq)
    shelves = feasible_df["location_id"].tolist()
    max_distance = feasible_df["distance"].max()

    for _ in range(N_EPISODES):
        action_shelf = _epsilon_greedy_select(q_table, bucket, shelves, EPSILON)
        dist = float(feasible_df.loc[feasible_df.location_id == action_shelf, "distance"].iloc[0])
        r = _reward(dist, max_distance, demand_freq)
        key = (bucket, action_shelf)
        old_q = q_table.get(key, 0.0)
        new_q = (1 - ALPHA) * old_q + ALPHA * r
        q_table[key] = new_q

    # Choose best shelf based on learned Q values
    best_shelf = None
    best_q = -float("inf")
    for sid in shelves:
        q = q_table.get((bucket, sid), 0.0)
        if q > best_q:
            best_q = q
            best_shelf = sid

    # Fallback if for some reason best_shelf is None
    if best_shelf is None:
        best_shelf = shelves[0]  # first feasible by distance

    # Persist placement
    new_row = {"item_id": new_item["item_id"], "recommended_location": best_shelf}
    placements_df = pd.concat([placements_df, pd.DataFrame([new_row])], ignore_index=True)
    placements_df.to_csv(PLACEMENTS_FILE, index=False)

    # Persist Q table
    _save_q_table(q_table)

    return f"New item {new_item['item_id']} placed at location {best_shelf}"


def _interactive_prompt() -> dict:
    print("Enter new item details (press Ctrl+C to cancel):")
    def _ask(prompt: str, cast, allow_empty=False):
        while True:
            val = input(prompt).strip()
            if not val and allow_empty:
                return None
            try:
                return cast(val) if cast else val
            except Exception:
                print("Invalid value, try again.")

    item_id = _ask("Item ID: ", str)
    demand = _ask("Demand frequency (number): ", float)
    dims = _ask("Dimensions (volume or HxWxD like 0.2x0.3x0.4): ", str)
    stock = _ask("Current stock (int): ", int)
    wpu = _ask("Weight per unit (number, default 1) : ", float)

    return {
        "item_id": item_id,
        "demand_frequency": demand,
        "dimensions": dims,
        "current_stock": stock,
        "weight_per_unit": wpu,
    }


def _demo():  # pragma: no cover
    sample_item = {"item_id": "ITEM_DEMO_001", "demand_frequency": 37, "dimensions": "0.3x0.3x0.4", "current_stock": 25, "weight_per_unit": 0.8}
    print(place_new_item(sample_item))


def main():  # pragma: no cover - CLI entry
    parser = argparse.ArgumentParser(description="Incremental RL-based placement")
    parser.add_argument("--demo", action="store_true", help="Run demo placement and exit")
    parser.add_argument("--interactive", action="store_true", help="Run interactive prompt for a single new item (default if no mode provided)")
    parser.add_argument("--batch", metavar="CSV", help="Process a CSV of new orders (columns: item_id,demand_frequency,dimensions,current_stock,weight_per_unit)")
    parser.add_argument("--layout", metavar="LAYOUT_CSV", help="Explicit layout file to use (overrides auto-detect)")
    parser.add_argument("--episodes", type=int, help="Override training episodes per item (default 40)")
    args = parser.parse_args()

    global N_EPISODES
    if args.episodes:
        N_EPISODES = args.episodes

    if args.demo:
        _demo()
        return 0

    if args.batch:
        if not os.path.exists(args.batch):
            print(f"[ERROR] Batch file not found: {args.batch}")
            return 1
        df_batch = pd.read_csv(args.batch)
        required_cols = {"item_id", "demand_frequency", "dimensions", "current_stock", "weight_per_unit"}
        missing = required_cols - set(df_batch.columns)
        if missing:
            print(f"[ERROR] Batch file missing columns: {missing}")
            return 1
        results = []
        for _, row in df_batch.iterrows():
            new_item = {
                "item_id": row["item_id"],
                "demand_frequency": row["demand_frequency"],
                "dimensions": row["dimensions"],
                "current_stock": row["current_stock"],
                "weight_per_unit": row["weight_per_unit"],
            }
            res = _place_new_item_core(new_item, layout_override=args.layout)
            results.append(res)
            print(res)
        print(f"Processed {len(results)} new orders.")
        return 0

    # Default interactive
    try:
        item = _interactive_prompt()
        result = _place_new_item_core(item, layout_override=args.layout)
        print("\n" + result)
    except KeyboardInterrupt:
        print("\nCancelled.")
        return 1
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
